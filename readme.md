# OcurusÂ Gazer

> **Webâ€‘cameraâ€“based 360Â° virtualâ€‘tour controller**Â Â Â Â·Â Â Â JavaScriptÂ / TypeScript Â· Runs fully in the browser Â· No server required

Â Â Â Â 

`ocurus-gazer` turns any ordinary webcam into a **handsâ€‘free navigation device** for spherical (equirectangular) panoramas and virtual tours. It is the gazeâ€‘tracking core we use inside [Ocurus.com](https://ocurus.com) but packaged as an openâ€‘source microâ€‘library so you can drop it into **Three.js**, **Aâ€‘Frame**, React, VueÂ or plain JS scenes.

---

## âœ¨Â Features

- **Zeroâ€‘setup** â€” import the ESM build, call `createGazer()`, thatâ€™s it.
- **MediaPipe Iris** landmarks for <2Â° angular error on most laptops.
- **Linear or ML gaze mapping** â€” start simple, switch to a CNN later without API changes.
- **Asymmetric blink detection** â€” rightâ€‘eye = *next*, leftâ€‘eye = *previous* scene.
- **Headâ€‘pose panning + eye microâ€‘adjust** â€” comfortable rotation without dizziness.
- **Optional Kalman filter** for butteryâ€‘smooth cursor.
- **No backend** â€” all inference runs in WebGL / WASM inside the browser.
- Written in **TypeScript**, ships with ESM/CJS/TypesÂ + declaration maps.

---

## ğŸš€Â QuickÂ start

```bash
# 1Â Â Install (npm, pnpm or yarn)
npm i ocurus-gazer

# 2Â Â Add to your TS / JS
import { createGazer } from 'ocurus-gazer';

const video = document.querySelector('#cam');
const stream = await navigator.mediaDevices.getUserMedia({ video: true });
video.srcObject = stream;
await video.play();

const gazer = await createGazer({ videoEl: video, model: 'iris', smoothing: true });

gazer.addListener(({ x, y, confidence }) => {
  // x, y âˆˆ [0,1]   â†’ map to panorama camera
});
```

Need a full example? See `` for a Three.js panorama that rotates as you move your head and blinks to jump between rooms.

---

## ğŸ› Â Folder structure

```
â”œâ”€ src/            # library source (TypeScript)
â”‚   â”œâ”€ gazer.ts    # core class
â”‚   â””â”€ index.ts    # tiny reâ€‘export wrapper
â”œâ”€ demo/           # standalone demo pages
â”œâ”€ test/           # Vitest specs
â”œâ”€ dist/           # build output (gitâ€‘ignored)
â””â”€ docs/           # screenshots, GIFs, design notes
```

---

## ğŸ“‘Â API

| Function                    | Description                                                    |
| --------------------------- | -------------------------------------------------------------- |
| `createGazer(cfg)`          | Asynchronously loads the model and returns a `Gazer` instance. |
| `addListener(fn)`           | Subscribe to realâ€‘time gaze points `{x,y,confidence,ts}`.      |
| `removeListener(fn)`        | Unsubscribe.                                                   |
| `beginCalibration(points?)` | Opens the 9â€‘point calibration UI (more coming soon).           |
| `pause()` / `resume()`      | Temporarily stop / continue inference.                         |
| `stop()`                    | Completely shut down and release the webcam stream.            |

See [API.md](API.md) for full type signatures and advanced options.

---

## ğŸ§‘â€ğŸ’»Â Development

```bash
# clone & bootstrap
git clone https://github.com/<YOUR-USER>/ocurus-gazer.git
cd ocurus-gazer && npm i

# run demo with hot reload
npm run dev

# typeâ€‘check, lint, test, bundle
npm run typecheck && npm run lint && npm run test && npm run build
```

The demo reloads instantly as you edit `src/gazer.ts`. Vitest runs inâ€‘memory; no browsers needed.

---

## ğŸ¤Â Contributing

Pull requests are welcomeÂ âœ¨.  Please open an issue first if you plan a large feature so we can discuss design.  By contributing you agree to release your code under the MIT license.

### Roadmap

-

---

## ğŸ“„Â License

**MIT** Â©Â 2025Â JavkhlanÂ Rentsendorj.  See [LICENSE](LICENSE) for details.

---

### Acknowledgements

Uses [MediaPipe](https://github.com/google/mediapipe) for landmark detection and was inspired by the fantastic work of WebGazer.js.

